{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的：对每个题目，评估他的难度等级，并且对不同难度等级的构造不同的分位数？这个看起来是一个比较直接的办法\n",
    "此外就是预测reasoning的长度，这个看起来是一种更灵活的方式\n",
    "或者把两个东西结合起来\n",
    "比如说实际当中，可以先用随机森林来预测，然后结合类别（比如说可以分成五类……）\n",
    "\n",
    "\n",
    "——————————\n",
    "需要做的事情：\n",
    "1. 完成conditional CP的代码（这个比较重要）（可以用他们的python包来预测）\n",
    "2. 完善预测的代码，用随机森林怎么才能用的更好一点点\n",
    "3. test 在新的数据上有多大的正确率，包括他的\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "如何真正的解决实际当中reasoning的问题呢？？？一般来说人们用conformal prediction是在提供一个置信区间\n",
    "更新overleaf，目前觉得用conditional 是一个不错的方法，但是实际中是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing problems: 138it [12:00,  5.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from plevel_tools.level_prompt import judge_level\n",
    "\n",
    "\n",
    "input_path = \"D:\\math\\A-reasoning_demo\\judged_datasets\\HuggingFaceH4\\MATH-500.jsonl\"\n",
    "output_path = \"D:\\math\\A-reasoning_demo\\judged_datasets\\HuggingFaceH4\\MATH-500_with_levels.jsonl\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-28d3e9b60f9f43a0a958ae132b7fcc2f\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_level(text):\n",
    "    match = re.search(r\"\\\\boxed\\{(\\d)\\}\", text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def query_with_retry(prompt, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[Retry {attempt+1}/{retries}] Error: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None \n",
    "\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in tqdm(infile, desc=\"Processing problems\"):\n",
    "        data = json.loads(line)\n",
    "        problem = data.get(\"problem\", \"\")\n",
    "\n",
    "        prompt = judge_level.format(problem=problem)\n",
    "        reply = query_with_retry(prompt, retries=3, delay=5)\n",
    "\n",
    "        if reply is not None:\n",
    "            level = extract_level(reply)\n",
    "            data[\"pred_level\"] = level\n",
    "        else:\n",
    "            data[\"pred_level\"] = None\n",
    "\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "i = 0\n",
    "with open (output_path,'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        a_data = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from conditionalconformal.synthetic_data import generate_cqr_data, indicator_matrix\n",
    "from conditionalconformal import CondConf\n",
    "\n",
    "problem_calib = []\n",
    "l_calib = []\n",
    "problem_test = []\n",
    "l_test = []\n",
    "i=0\n",
    "\n",
    "\n",
    "with open (output_path,'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        i+=1\n",
    "        if(i<=100):\n",
    "            data = json.loads(line)\n",
    "            problem_calib.append({\"problem\":data.get(\"problem\", \"\"),\"level\":data.get(\"pred_level\",\"\")})\n",
    "            l_calib.append(data.get(\"min_valid_length\",\"\"))\n",
    "        else:\n",
    "            data = json.loads(line)\n",
    "            problem_test.append({\"problem\":data.get(\"problem\", \"\"),\"level\":data.get(\"pred_level\",\"\")})\n",
    "            l_test.append(data.get(\"min_valid_length\",\"\"))\n",
    "alpha = 0.1\n",
    "\n",
    "score_fn = lambda x,y: y\n",
    "score_inv_fn_lb = lambda s, x : [s, np.inf]\n",
    "\n",
    "eps = 1\n",
    "disc = np.arange(0.5, 5 + eps, eps) \n",
    "def phi_fn_groups(x):\n",
    "    levels = [data[\"level\"] for data in x]\n",
    "    return indicator_matrix(levels, disc)\n",
    "\n",
    "cond_conf = CondConf(score_fn,phi_fn_groups,infinite_params={})\n",
    "cond_conf.setup_problem(x_calib=problem_calib,y_calib=l_calib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
