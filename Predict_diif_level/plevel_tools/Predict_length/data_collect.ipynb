{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"open-thoughts/OpenThoughts-114k\", \"metadata\", split=\"train[:10%]\")\n",
    "problems = dataset['problem']\n",
    "Reasoning = dataset['deepseek_reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "def compute_token_lengths(texts, tokenizer):\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=16384)\n",
    "    r_l = torch.sum(encodings['attention_mask'],dim=1)\n",
    "    return r_l\n",
    "\n",
    "reasoning_l = compute_token_lengths(Reasoning,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reasoning_l.shape)\n",
    "model = SentenceTransformer(\"sentence-transformers/LaBSE\",device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pl_tools.tools import compress\n",
    "# model = SentenceTransformer(\"sentence-transformers/LaBSE\",device='cuda')\n",
    "problems_embeddings = model.encode(problems)\n",
    "problems_embeddings = torch.tensor(problems_embeddings)\n",
    "compressed_eb = compress(problems_embeddings,d=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "compressed_eb_list = compressed_eb.tolist()\n",
    "r_l_list = reasoning_l.tolist()\n",
    "data = [\n",
    "    {\n",
    "        \"problem\": problem,\n",
    "        \"embedding\": embedding,\n",
    "        \"reasoning_length\": r_l,\n",
    "        \"problem_length\":len(problem)\n",
    "    }\n",
    "    for problem, embedding, r_l in zip(problems, compressed_eb_list, r_l_list)\n",
    "]\n",
    "\n",
    "with open(\"problems_with_embeddings.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "problem_length = [len(problem) for problem in problems]\n",
    "X_length = np.array(problem_length).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib  \n",
    "\n",
    "X_embed = compressed_eb.cpu().numpy() if isinstance(compressed_eb, torch.Tensor) else compressed_eb\n",
    "X_length = np.array(problem_length).reshape(-1, 1)\n",
    "y = np.array(reasoning_l)\n",
    "\n",
    "X = np.concatenate([X_length, X_embed], axis=1)  # Shape: [, 17]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "regressor = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=5,\n",
    "    min_samples_split=10,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "val_preds = regressor.predict(X_val)\n",
    "val_mse = np.mean((val_preds - y_val) ** 2)\n",
    "print(f\"valid MSEï¼š{val_mse:.2f}\")\n",
    "\n",
    "joblib.dump(regressor, \"random_forest_regressor.pkl\")\n",
    "print(\"the model is saved to random_forest_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "train_pred = regressor.predict(X_train)\n",
    "plt.scatter(y_train, train_pred, alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val, val_preds, alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "with open(\"problems_with_embeddings.json\",\"r\",encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "reasoning_lengths = [item['reasoning_length'] for item in data]\n",
    "df = pd.DataFrame(reasoning_lengths, columns=[\"reasoning_length\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = df[\"reasoning_length\"].quantile([0.2, 0.4, 0.6, 0.8])\n",
    "print(quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
